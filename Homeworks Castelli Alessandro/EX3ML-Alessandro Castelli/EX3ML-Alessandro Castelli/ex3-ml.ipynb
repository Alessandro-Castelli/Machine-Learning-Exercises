{"cells":[{"cell_type":"markdown","metadata":{},"source":["Kaggle competition: https://www.kaggle.com/c/digit-recognizer/"]},{"cell_type":"markdown","metadata":{},"source":["## WANDB link: https://wandb.ai/ales-2000-09/digit_recognizer?workspace=user-ales-2000-09\n","## Alessandro Castelli code link: https://www.kaggle.com/code/alessandromajumba/ex3-ml\n","\n","### Best Score = 0.979"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"markdown","metadata":{},"source":["We need to import Torch's libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import torchvision\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import transforms\n","from torch.utils.data import DataLoader, Dataset\n","\n","from kaggle_secrets import UserSecretsClient\n","user_secrets = UserSecretsClient()\n","secret_value_0 = user_secrets.get_secret(\"Label\")\n","\n","import wandb\n","wandb.login(key=secret_value_0)\n","wandb.init(project='digit_recognizer', save_code=True)"]},{"cell_type":"markdown","metadata":{},"source":["## Data preparation\n","\n","A custom dataset which uses the CSV from Kaggle, avoid downloading the dataset from internet"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class MyMNISTDataset(Dataset):\n","    \n","    def __init__(self, file_path, transform = transforms.Compose([transforms.ToPILImage()]), test_data=False, use_gpu=torch.cuda.is_available()):\n","        # read the data\n","        df = pd.read_csv(file_path)\n","        # for test data we don't have any target\n","        # MNIST images are 28 by 28, grey colors\n","        if test_data:\n","            self.X = df.values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]\n","            self.y = None\n","        else:\n","            self.X = df.iloc[:,1:].values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]\n","            self.y = torch.from_numpy(df.iloc[:,0].values)\n","        self.transform = transform\n","        self.use_gpu = use_gpu\n","    \n","    def __len__(self):\n","        return len(self.X)\n","\n","    def __getitem__(self, idx):\n","        data = self.transform(self.X[idx])\n","        if self.y is not None:\n","            target = self.y[idx]\n","            if self.use_gpu:\n","                data = data.cuda()\n","                target = target.cuda()\n","            return data, target\n","        else:\n","            if self.use_gpu:\n","                data = data.cuda()\n","            return data"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from torch.utils.data.sampler import SubsetRandomSampler\n","\n","transformations=transforms.Compose([transforms.ToPILImage(), \n","                                    transforms.ToTensor(), \n","                                    transforms.Normalize(mean=(0.5,), std=(0.5,))])\n","\n","train_dataset = MyMNISTDataset('/kaggle/input/digit-recognizer/train.csv', transform=transformations, test_data=False)\n","test_dataset = MyMNISTDataset('/kaggle/input/digit-recognizer/test.csv', transform=transformations, test_data=True)\n","\n","# create data loader for train and test set\n","\n","# Define the size of validation set\n","validation_split = 0.2\n","dataset_size = len(train_dataset)\n","indices = list(range(dataset_size))\n","split = int(np.floor(validation_split * dataset_size))\n","\n","# Shuffle the indices\n","np.random.shuffle(indices)\n","\n","# Split the indices into training and validation sets\n","train_indices, val_indices = indices[split:], indices[:split]\n","\n","# Create the samplers\n","train_sampler = SubsetRandomSampler(train_indices)\n","val_sampler = SubsetRandomSampler(val_indices)\n","\n","# Create the data loaders\n","train_loader = DataLoader(train_dataset, batch_size=64, sampler=train_sampler)\n","val_loader = DataLoader(train_dataset, batch_size=64, sampler=val_sampler)\n","test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)  # For the test set, we use shuffle=False\n"]},{"cell_type":"markdown","metadata":{},"source":["## MLP\n","\n","### Define model architecture\n","You need to reach at least 70% accuracy on the test set"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2023-12-08T18:15:01.793286Z","start_time":"2023-12-08T18:15:01.780071Z"},"trusted":true},"outputs":[],"source":["class Net(nn.Module):    \n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.fc1 = nn.Linear(28 * 28, 512) # Adjust input size based on your image dimensions\n","        self.fc2 = nn.Linear(512, 256)\n","        self.fc3 = nn.Linear(256, 10) # Output size corresponds to the number of classes\n","        self.dropout = nn.Dropout(0.2)\n","        \n","    def forward(self, x):\n","        x = x.view(-1, 28 * 28)  # Flatten the input\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","\n","        x = self.dropout(x)\n","        \n","        x = self.fc3(x)\n","        return x\n","\n","# Create an instance of the Net model\n","model = Net()#.to(device)\n","\n","# If using GPU, move the model to GPU\n","if torch.cuda.is_available():\n","    model.cuda()\n","\n","# Print the model architecture\n","print(model)\n"]},{"cell_type":"markdown","metadata":{},"source":["### Init the model and put it on GPU/TPU"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# let use the model on the GPU\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print('Using device:', device)\n","\n","print(model)\n","\n","lr = 0.1\n","wandb.log({'learning rate': lr})\n","\n","#Cross-Entropy as Loss function\n","criterion = nn.CrossEntropyLoss()\n","\n","#SGD optimizer\n","optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n","wandb.log({'optimizer':'SGD'})\n","\n","#This is another optimizer\n","# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","# wandb.log({'optimizer':'ADAM'})"]},{"cell_type":"markdown","metadata":{},"source":["### Training loop\n","Log the accuracy and the loss to wandb"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# number of epochs \n","n_epochs = 40\n","mean_train = []\n","mean_valid = []\n","valid_acc = []\n","#Save on WANDB\n","wandb.log({'num_epochs': n_epochs})\n","\n","#Start training\n","for epoch in range(n_epochs):\n","    train_losses = []\n","    valid_losses = []\n","\n","    model.train() \n","    for data, target in train_loader:\n","        data=data.to(device)\n","        target=target.to(device)\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = criterion(output, target)\n","        loss.backward()\n","        optimizer.step()\n","        train_losses.append(loss.item())\n","        \n","#start evaluation\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for data, target in val_loader:\n","            data=data.to(device)\n","            target=target.to(device)\n","            output = model(data)\n","            loss = criterion(output, target)\n","            valid_losses.append(loss.item())\n","            \n","            _, predicted = torch.max(output.data, 1)\n","            correct += (predicted == target).sum().item()\n","            total += target.size(0)\n","\n","    mean_train.append(np.mean(train_losses))\n","    mean_valid.append(np.mean(valid_losses))\n","    \n","    accuracy = 100*correct/total\n","    valid_acc.append(accuracy)\n","    #Print the results\n","    print('epoch : {}, train loss : {:.4f}, valid loss : {:.4f}, valid acc : {:.2f}%'\\\n","         .format(epoch+1, np.mean(train_losses), np.mean(valid_losses), accuracy))\n","    \n","    #Save on WANDB\n","    wandb.log({'train_loss':mean_train[-1]})\n","    wandb.log({'val_loss':mean_valid[-1]})\n","    wandb.log({'val_accuracy':valid_acc[-1]})"]},{"cell_type":"markdown","metadata":{},"source":["### Make prediction\n","And submit to Kaggle for grading"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["with torch.no_grad():\n","    model.eval()\n","    test_pred = torch.LongTensor()\n","    for i, data in enumerate(test_loader):\n","        output = model(data)\n","        _, predicted = torch.max(output.data, 1)\n","        predicted = predicted.cpu()\n","        test_pred = torch.cat((test_pred, predicted), dim=0)\n","    out_df = pd.DataFrame(np.c_[np.arange(1, len(test_dataset)+1)[:,None], test_pred.numpy()], columns=['ImageId', 'Label'])\n","    out_df.to_csv('submission.csv', index=False)"]},{"cell_type":"markdown","metadata":{},"source":["### Top 10 misclassified images by class probability"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","batch_size=64\n","unshuffle_train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n","                                           batch_size=batch_size, shuffle=False)\n","with torch.no_grad():\n","    model.eval()\n","    missclasified = torch.DoubleTensor()\n","    for batch_idx, (data, target) in enumerate(unshuffle_train_loader):\n","        output = model(data)\n","        prob, predicted = torch.max(output.data, 1)\n","        predicted = predicted.cpu()\n","        target = target.cpu()\n","        prob = prob.cpu().double()\n","        missclassified_prob = torch.where(predicted == target, 0., prob)\n","        missclasified = torch.cat((missclasified, missclassified_prob), dim=0)\n","    most_misclassified = torch.argsort(missclasified, descending=True)\n","    top_ten_misclassified = most_misclassified[:10]"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["for misclassified in top_ten_misclassified:\n","    plt.imshow(train_dataset[misclassified][0].cpu().reshape(28,28))\n","    with torch.no_grad():\n","        data, target = train_dataset[misclassified]\n","        data = data.reshape(1, 1, 28,28)\n","        output = model(data)\n","        _, predicted = torch.max(output.data, 1)\n","        plt.title(f'Predicted: {predicted.item()}, Ground truth: {target}')\n","    plt.show()"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"databundleVersionId":861823,"sourceId":3004,"sourceType":"competition"}],"dockerImageVersionId":30627,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
